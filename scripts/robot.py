#!/usr/bin/env python
'''
Author: Lucas Tindall

This project combines pa1 and pa3 to perform "path planning without perfect state information". 
The robot starts in a random location and uses the temperature and sensor readings to localize itself. 
After updating its position beliefs it executes a move based on the decision policies generated by the algorithm 
from pa3. The robot selects the policy from the square with the greatest belief. The robot then updates its position beliefs 
based off of that movement. The map is surrounded by walls and has additional walls within it. The motion is uncertain 
which has advantages and disadvantages. When the robot initially localizes itself very well and then moves incorrectly 
it can take longer to get to the goal. If the robot gets stuck because it incorrectly localized itself, then the uncertain 
motion can also help alleviate that problem. With an 11x11 map the robot was allways able to reach the goal within a minute, 
even if it got stuck along the way. While the robot is moving it does not know for certain which square it is in so it relies on  
a special topic called /found_goal which publishes True when the robot has reached the goal. 

The sensor models are the same as they were in pa1 but have been slighly tweaked to account for walls. 
Motion is uncertain. 
There is a negative reward for making movements and for hitting walls. There is positive reward for getting to the goal. 

I thought of this project as a robot being dropped on some planet and having to travel to a specific location without 
knowing exactly where it was dropped. The robot would have a detailed map of the planet and be able to take sensor readings
which could be combined to create a belief about its position. The robot would also be able to find an optimal policy for each 
location on the map. With a map that is large enough and without too many obstacles, the robot would always be able to find 
its goal. Although the robot would never know for certain where it was, the goal would have some kind of sensor which alerts 
the robot that it has reached its desired destination. 

'''
from __future__ import division
import rospy
import itertools
import random as r
import math as m
import numpy as np
import image_util
from copy import deepcopy
from std_msgs.msg import String, Float32, Bool
from cse_190_assi_4.msg import temperatureMessage, RobotProbabilities, PolicyList, RobotLocation
from cse_190_assi_4.srv import requestMapData, moveService, requestTexture
from read_config import read_config
from mdp import mdp 
from util import print_2d_floats



class robot():
    def __init__(self):
        """Read config file and setup ROS things"""
        self.config = read_config()


        rospy.init_node("robot")
	self.temperature_sensor_activation = rospy.Publisher(
                "/temp_sensor/activation",
                Bool,
                queue_size = 10
        )
	self.temperature_sensor_data = rospy.Subscriber(
                "/temp_sensor/data",
                temperatureMessage,
                self.handle_temperature_sensor_data
        )
	self.robot_texture_requester = rospy.ServiceProxy(
                "requestTexture",
                requestTexture
        )
	self.robot_move_requester = rospy.ServiceProxy(
                "moveService",
                moveService
        )
	self.position_publisher = rospy.Publisher(
                "/results/probabilities",
                RobotProbabilities,
                queue_size = 10
        )
	self.temperature_publisher = rospy.Publisher(
                "/results/temperature_data",
                Float32,
                queue_size = 10
        )
	self.texture_publisher = rospy.Publisher(
                "/results/texture_data",
                String,
                queue_size = 10
        )
	self.simulation_complete_publisher = rospy.Publisher(
                "/map_node/sim_complete",
                Bool,
                queue_size = 10
        )
	self.temperature_requester = rospy.ServiceProxy(
                "requestMapData",
                requestMapData
        )
        self.policy_publisher = rospy.Publisher(
            "/results/policy_list",
            PolicyList,
            queue_size = 10
        )
	self.found_goal_subscriber = rospy.Subscriber(
                "/found_goal",
                Bool,
                self.handle_found_goal
        )
	self.temp_dict = {
                'H': 40.0,
                'C': 20.0,
                '-': 25.0
        }
	self.policy_dict = {
		'N': [-1,0], 
		'S': [1,0], 
		'E': [0,1], 
		'W': [0,-1],
		'GOAL':[0,0]
	}
	
	# wait for publishers to be created 
	rospy.sleep(3)
	
	self.foundGoal = False 
	self.iteration_number = 0 
	######################
	# SETUP FOR PLATH PLANNING (MDP PA 3) 
 	########################

	map_size = self.config['map_size']
        rows = map_size[0]
        columns = map_size[1]
        goal = self.config['goal']
        walls = self.config['walls']
        pits = self.config['pits']
        move_list = self.config['mdp_move_list']


        oldV = [[0 for x in range(columns)] for y in range(rows)]

        # initialize V values 
        #oldV = [[0 for x in range(columns)] for y in range(rows)]              
        for i in range(rows):
            for j in range(columns):
                tempGrid = [i,j]
                if tempGrid == goal:
                    oldV[i][j] = self.config['reward_for_reaching_goal']
                elif tempGrid in walls:
                    oldV[i][j] = self.config['reward_for_hitting_wall']
                elif tempGrid in pits:
                    oldV[i][j] = self.config['reward_for_falling_in_pit']
                else:
                    #this is redundant 
                    oldV[i][j] = 0

        stoppingSum = 0
        firstThreshold = False
        secondThreshold = False
        firstX = 0
        secondX = -100
	
	self.policiesFlat = []
	for x in range(self.config['max_iterations']):
            mdpPolicy = mdp(self.config,oldV)
            self.policiesFlat = mdpPolicy.policies
            self.policy_publisher.publish(self.policiesFlat)
            for i in range(rows):
                for j in range(columns):
                    stoppingSum += abs(oldV[i][j]-mdpPolicy.newV[i][j])
            if(stoppingSum < self.config['threshold_difference']):
                secondX = x
            if(secondX - 1 == firstX ):
                break
            if(stoppingSum < self.config['threshold_difference'] ):
                firstX = x
                firstThreshold = True

            oldV = mdpPolicy.newV

	i = 0 
	self.policies = []
	while i < (rows*columns): 
	    self.policies.append(self.policiesFlat[i:i+columns])
	    i += columns 
	
	#print "PRINTING POLICIES = ",self.policies
	rospy.sleep(5)

	####################
	# SETUP FOR LOCALIZATION (PA 1) 
	####################

	self.temp_map = self.config['pipe_map']
	self.tex_map = self.config['texture_map']
	self.std_dev = self.config['temp_noise_std_dev'] 
	self.move_index = 0 
	self.moves = self.config['move_list']
	
        self.num_rows = len(self.config['pipe_map'])
        self.num_cols = len(self.config['pipe_map'][0])
	
	self.positions = []
	self.numValidSquares = (self.num_rows*self.num_cols) - (2*self.num_rows + 2*(self.num_cols-2))
	#print "numValidSquares: ",self.numValidSquares
	for i in range(self.num_rows):
	    rowPositions = []
	    for j in range(self.num_cols):  
		if(i == 0 or i == self.num_rows-1 or j == 0 or j == self.num_cols -1 ): 
		    rowPositions.append(0)
		else: 
	    	    rowPositions.append(1/self.numValidSquares)
	    self.positions.append(rowPositions)
	#print "self.positions: ",self.positions
	#print "initial positions ",self.positions
	rospy.sleep(2)
	self.processing = False 
	self.temperature_sensor_activation.publish(True)
        
        rospy.spin()

    def handle_found_goal(self,message): 
	self.foundGoal = True 


    def convert_list_to_2d_array(self, policy_list):
        x, y = self.config["map_size"]
        return [policy_list[i : i + y] for i in xrange(0, len(policy_list), y)]

    """
    Callback function for the temperature sensor data subscriber 

    Each time the robot receives new data from the temperature sensor
    it should request data from the texture sensor using the ServiceProxy
    robot_texture_requester and then move the robot using the 
    ServiceProxy robot_move_requester. 
    """
    def handle_temperature_sensor_data(self, message): 
	while(self.processing != False): 
	    pass
	#rospy.sleep(2)
	self.process(message)


    """
	Called by handle_temperature_sensor_data to signal that the beliefs 
	should be recalculated and the robot should make a move based on those
	new beliefs. 

	The robot makes its move based on the optimal policy for whichever 
	square has the highest belief. 
    """
    def process(self,message):
	# start processing 
	self.processing = True

	# Get sensor readings
 	temperature = message.temperature
	texture_response = self.robot_texture_requester()
	texture = texture_response.data
	
	# Prepare to update position 
	temporary_temp_pos = [] 
	normalization_constant = 0.0


	# Calculate position based on temperature sensor  
	for i in range(self.num_rows): 
	    tempRow = []
	    for j in range(self.num_cols):
		if([i,j] in self.config['walls']): 
		    tempRow.append(0)
		else: 
		    #print "problem ", self.temp_map[i][j]
	            expected_temp = self.temp_dict[self.temp_map[i][j]]
	            tempRow.append(((1/(self.std_dev * m.sqrt(2*m.pi))) *
			 m.pow(m.e,-1*(m.pow((temperature-expected_temp),2))/
	                 (2*m.pow(self.std_dev,2))))*self.positions[i][j])
	        normalization_constant += tempRow[j]
	    temporary_temp_pos.append(tempRow)
	for i in range(self.num_rows):
	    for j in range(self.num_cols):  
	        self.positions[i][j]=(temporary_temp_pos[i][j]/normalization_constant)
	#print "normalized positions: ",self.positions
	#print "Temperature ",temperature	

	# publish temperatures
	self.temperature_publisher.publish(temperature) 
	

	# Calculate position based on texture sensor
	normalization_constant = 0.0
	temporary_tex_pos = []

	for i in range(self.num_rows):
	    tempTexRow = [] 
	    for j in range(self.num_cols): 
		if([i,j] in self.config['walls']): 
		    tempTexRow.append(0)
		else: 
	            expected_tex = self.tex_map[i][j]
	            if (texture == expected_tex): 
	                prob_tex_given_x = self.config['prob_tex_correct']
                    else: 
		        prob_tex_given_x = 1-self.config['prob_tex_correct'] 
	            tempTexRow.append(prob_tex_given_x * self.positions[i][j] )
                normalization_constant += tempTexRow[j]
	    temporary_tex_pos.append(tempTexRow)
	for i in range(self.num_rows): 
	    for j in range(self.num_cols): 
	        self.positions[i][j] = (temporary_tex_pos[i][j]/normalization_constant)

	# publish textures 
	self.texture_publisher.publish(texture)
	
	
        # make copy of position beliefs 
	formated_positions_copy = deepcopy(self.positions)


	##################
	# End of recomputing position based on sensors 
        ##################
	

	#################
	# FIND POSITION WITH HIGHEST PROBABILITY 
	# AND MOVE ACCORDING TO THE POLICY FOR THAT SQUARE 
	######################
	maxProb = 0
	maxProbIndex = []
	for i in range(self.num_rows): 
	    for j in range(self.num_cols): 
	        if(self.positions[i][j] > maxProb): 
		    maxProb = self.positions[i][j]
		    maxProbIndex = [i,j]
	#########################################

	# print out debugging info 
	print "ROBOT HAS HIGHEST LIKELIHOOD AT INDEX: ",maxProbIndex
        print "HIGHEST LIKELIHOOD: ",maxProb


	##########################
	# MOVE ROBOT 
	###########################
	print "OPTIMAL MOVE: ",self.policies[maxProbIndex[0]][maxProbIndex[1]]
        self.robot_move_requester(self.policy_dict[self.policies[maxProbIndex[0]][maxProbIndex[1]]]) 
        #print "Move ",self.moves[self.move_index]

	###########################
	# CREATE IMAGE FOR VIDEO 
	##############################
	# This is handled by RobotLogger whenever the /robot_location topic 
	# gets a new message 	

	#########################
	# IF ROBOT IS AT GOAL THEN STOP SIMULATION
	# *ASSUME ROBOT HAS SOME SPECIAL SENSOR WHICH ACTIVATES  
	# WHEN IT ARRIVES AT THE GOAL
	# * self.foundGoal is set by the handle_found_goal callback above 
	#################################	
	if(self.foundGoal == True): 
	    #image_util.generate_video(self.iteration_number)
	    self.simulation_complete_publisher.publish(True)
	    rospy.sleep(5)
    	    rospy.signal_shutdown("Completed all moves, shutting down")
		
	
	# Calculate position based on movement  
	expected_move = self.policy_dict[self.policies[maxProbIndex[0]][maxProbIndex[1]]]
	for i in range(self.num_rows): 
	    for j in range(self.num_cols): 
	        formated_positions_copy[i][j] = 0
		for move in self.config['possible_moves']:
		    if expected_move == move: 
			prob_move = self.config['prob_move_correct']
		    else: 
			prob_move = (1-self.config['prob_move_correct'])/(
				    len(self.config['possible_moves'])-1)
		    if([i,j] not in self.config['walls']):
		        formated_positions_copy[i][j] += self.positions[(i-move[0])%self.num_rows][(j-move[1])%self.num_cols] * prob_move
	
	flattened_positions = list(itertools.chain.from_iterable(formated_positions_copy))
        self.positions = formated_positions_copy
	#print "FINAL POSITIONS: ",self.positions

	###########################
	# PRETTY PRINT THE BELIEF MAP
	##########################	
	print_2d_floats(self.positions)
	#print "Positions ",flattened_positions



	self.position_publisher.publish(flattened_positions) 

	
        self.move_index += 1 
	self.processing = False
	
	
if __name__ == '__main__':
    robo = robot()
